{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf66e795-5d8c-4233-a74a-6d02afbea5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import mimetypes\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore.client import Config\n",
    "\n",
    "BUCKET_NAME = 'urban-heat-files'\n",
    "DATA_FOLDER = Path('../_data/final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2984e6d-2f47-4395-a1f5-27db7370ed9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup s3 \n",
    "def s3_client(aws_id, aws_key):\n",
    "\ts3 = boto3.client(\n",
    "\t\t's3',\n",
    "\t\taws_access_key_id=aws_id,\n",
    "\t\taws_secret_access_key=aws_key,\n",
    "\t\tconfig=Config(connect_timeout=10, read_timeout=100, retries={'max_attempts': 10})\n",
    "\t)\n",
    "\treturn s3\n",
    "\n",
    "def put_object(s3_client, dest_bucket_name, dest_object_name, src_data, content_type, cache_control=''):\n",
    "\t\"\"\"Add an object to an Amazon S3 bucket\n",
    "\n",
    "    https://docs.aws.amazon.com/code-samples/latest/catalog/python-s3-put_object.py.html\n",
    "\n",
    "\tThe src_data argument must be of type bytes or a string that references\n",
    "\ta file specification.\n",
    "\n",
    "    :param s3_client: s3_client as returned by s3_client()\n",
    "\t:param dest_bucket_name: string\n",
    "\t:param dest_object_name: string\n",
    "\t:param src_data: bytes of data or string reference to file spec\n",
    "\t:param content_type: string to set for Content-Type header on file\n",
    "\t:param cache_control: string to set for Cache-Control header on file (if not provided, header not set)\n",
    "\t:return: True if src_data was added to dest_bucket/dest_object, otherwise\n",
    "\tFalse\n",
    "\t\"\"\"\n",
    "\t# Construct Body= parameter\n",
    "\tif isinstance(src_data, bytes):\n",
    "\t\tobject_data = src_data\n",
    "\telif isinstance(src_data, str):\n",
    "\t\ttry:\n",
    "\t\t\tobject_data = open(src_data, 'rb')\n",
    "\t\t\t# possible FileNotFoundError/IOError exception\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tlogging.error(e)\n",
    "\t\t\treturn False\n",
    "\telse:\n",
    "\t\tlogging.error('Type of ' + str(type(src_data)) +\n",
    "\t\t\t\t\t  ' for the argument \\'src_data\\' is not supported.')\n",
    "\t\treturn False\n",
    "\n",
    "\tkwargs = {\n",
    "\t\t'Bucket': dest_bucket_name, \n",
    "\t\t'Key': dest_object_name, \n",
    "\t\t'Body': object_data,\n",
    "\t\t'ContentType': content_type\n",
    "\t}\n",
    "\n",
    "\tif cache_control != '':\n",
    "\t\tkwargs['CacheControl'] = cache_control\n",
    "\n",
    "\ttry:\n",
    "\t\ts3_client.put_object(**kwargs)\n",
    "\texcept ClientError as e:\n",
    "\t\t# AllAccessDisabled error == bucket not found\n",
    "\t\t# NoSuchKey or InvalidRequest error == (dest bucket/obj == src bucket/obj)\n",
    "\t\tlogging.error(e)\n",
    "\t\treturn False\n",
    "\tfinally:\n",
    "\t\tif isinstance(src_data, str):\n",
    "\t\t\tobject_data.close()\n",
    "\treturn True\n",
    "    \n",
    "class S3:\n",
    "\t\"\"\"AWS S3 client for getting/putting objects to/from oca-data bucket\"\"\"\n",
    "\tdef __init__(self, aws_id, aws_key, aws_bucket_name):\n",
    "\t\tself.s3 = s3_client(aws_id, aws_key)\n",
    "\t\tself.bucket_name = aws_bucket_name\n",
    "\n",
    "\tdef upload_file(self, object_name, file_path, content_type):\n",
    "\t\text = os.path.splitext(file_path)[1]\n",
    "\n",
    "\t\t# date-updated image needs to have no-cache to be used in github readme\n",
    "\t\tcache_control = 'no-cache' if content_type == 'image/png' else ''\n",
    "\n",
    "\t\t# Put the object into the bucket\n",
    "\t\tput_object(self.s3, self.bucket_name, object_name, str(file_path), content_type, cache_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af981bdc-f6d4-48c3-b80c-cdca91354400",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = S3(os.environ['AWS_ACCESS_KEY_ID'], os.environ['AWS_SECRET_ACCESS_KEY'], BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118f481-bbe6-43f3-be5e-5cb6830541ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files in final folder and upload\n",
    "for file_path in DATA_FOLDER.iterdir():\n",
    "    if file_path.stem not in ('.gitkeep'): # skip .gitkeep and other files \n",
    "        # todo- check if there is a difference between what's on the s3 and local\n",
    "        mime_type, _ = mimetypes.guess_type(file_path)\n",
    "        print(file_path.name, mime_type)\n",
    "        s3.upload_file(f\"{file_path.name}\", file_path, mime_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
